# ============================================================================
# LinkedIn Sourcing Agent Configuration
# ============================================================================

# ðŸŽ¯ SETUP OPTIONS: Choose one of the following
# ============================================================================

# OPTION A: FREE LOCAL AI (Most Private)
# Using Ollama for local AI processing - completely free and private
# USE_OPEN_SOURCE_MODEL=true
# OPEN_SOURCE_MODEL_TYPE=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2:3b

# OPTION B: GOOGLE GEMINI (Free Tier Available)
# Uncomment these lines and comment out Ollama settings above to use Gemini
USE_OPEN_SOURCE_MODEL=false
USE_GEMINI=true
GEMINI_MODEL=gemini-1.5-flash
GOOGLE_GEMINI_API_KEY=AIzaSyAEVl6ziWDIe0E1bNUyM6AWa2x00wM-qmw

# ============================================================================
# API KEYS
# ============================================================================
OPENAI_API_KEY=
RAPIDAPI_KEY=
HUGGINGFACE_API_KEY=
GOOGLE_GEMINI_API_KEY=AIzaSyAEVl6ziWDIe0E1bNUyM6AWa2x00wM-qmw

# ============================================================================
# SYSTEM SETTINGS
# ============================================================================
# Rate limiting configuration
MAX_REQUESTS_PER_MINUTE=30
BATCH_SIZE=5

# Caching settings
ENABLE_CACHING=true
CACHE_EXPIRY_HOURS=24

# Multi-source enhancement
ENABLE_MULTI_SOURCE=true

# GitHub API (for enhanced profiles)
GITHUB_API_KEY=

# Twitter API (for social presence)
TWITTER_BEARER_TOKEN=

# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
# 1. Install Ollama: https://ollama.ai/
# 2. Run: ollama pull llama3.2:3b
# 3. Start Ollama service
# 4. Run: python main.py
# ============================================================================
